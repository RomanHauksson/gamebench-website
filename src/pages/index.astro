---
import { Image } from "astro:assets";

import Layout from "../layouts/Layout.astro";
import Video from "../components/Video.astro";
import Links from "../components/Links.astro";
import AuthorList from "../components/AuthorList.astro";
import Section from "../components/Section.astro";
import YouTubeVideo from "../components/YouTubeVideo.astro";
import PDF from "../components/PDF.astro";

import outside from "../assets/outside.mp4";
import transformer from "../assets/transformer.webp";
import overallRating from "../assets/overall_rating.png";
import ratingScatter from "../assets/rating_scatter.png";

const title =
  "GameBench: Evaluating Strategic Reasoning Abilities of LLM Agents";
---

<Layout title={title}>
  <header class="flex flex-col gap-8 items-center">
    <h1 class="text-5xl text-center font-medium">{title}</h1>
    <AuthorList
      authors={[
        {
          name: "Anthony Costarelli",
          institution: "Olin College of Engineering",
          notes: ["*"],
        },
        {
          name: "Mat Allen",
          institution: "Independent",
          notes: ["*"],
        },
        {
          name: "Roman Hauksson",
          url: "https://roman.technology",
          institution: "University of Texas at Dallas",
          notes: ["*"],
        },
        {
          name: "Grace Sodunke",
          institution: "University of Oxford",
          notes: ["*"],
        },
        {
          name: "Suhas Hariharan",
          institution: "University College London",
        },
        {
          name: "Carlson Cheng",
          institution: "Independent",
        },
        {
          name: "Wenjie Li",
          institution: "ShanghaiTech University",
        },
        {
          name: "Arjun Yadav",
          institution: "University of Manchester",
        },
      ]}
    />
    <!-- <p class="text-xl">Conference Name</p> -->
    <p class="text-sm">
      <sup>*</sup>Equal contribution. Correspondence to acostarelli@olin.edu.
    </p>
    <Links
      links={[
        {
          name: "Paper",
          url: "https://arxiv.org/pdf/2406.06613",
          icon: "fa-solid:file-pdf",
        },
        {
          name: "Code",
          url: "https://github.com/Joshuaclymer/GameBench",
          icon: "mdi:github",
        },
        {
          name: "arXiv",
          url: "https://arxiv.org/abs/2406.06613",
          icon: "academicons:arxiv",
        },
      ]}
    />

    <!-- <Video
      source={outside}
      caption="Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus."
    /> -->
  </header>

  <main class="flex flex-col gap-8 items-center">
    <Section title="">
      <p class="text-lg">
        Large language models have demonstrated remarkable few-shot performance
        on many natural language understanding tasks. Despite several
        demonstrations of using large language models in complex, strategic
        scenarios, there lacks a comprehensive framework for evaluating agents’
        performance across various types of reasoning found in games. To address
        this gap, we introduce GAMEBENCH, a cross-domain benchmark for
        evaluating strategic reasoning abilities of LLM agents. We focus on 9
        different game environments, where each covers at least one axis of key
        reasoning skill identified in strategy games, and select games for which
        strategy explanations are unlikely to form a significant portion of
        models’ pretraining corpuses. Our evaluations use GPT-3 and GPT-4 in
        their base form along with two scaffolding frameworks designed to
        enhance strategic reasoning ability: Chain-of-Thought (CoT) prompting
        and Reasoning Via Planning (RAP).
      </p>
    </Section>

    <Section title="Results">
      <p class="text-xl">
        With CoT scaffolding, GPT-4 is the best reasoner below only the human
        baseline, achieving the best performance on Sea Battle and Pit. But
        without scaffolding, it performs worse than even the random baseline due
        to its exceedingly low rating on Sea Battle. The state-of-the-art RAP
        scaffolding doesn’t provide as much of an improvement to GPT-4 as CoT
        does.
      </p>
      <figure class="self-center flex flex-col gap-2">
        <Image
          class="max-h-[30rem] w-auto rounded-lg m-auto"
          src={overallRating}
          alt="alt text"
        />
        <figcaption class="text-lg text-center text-slate-700">
          Aggregated strategic reasoning scores for each tested
          model–scaffolding configuration, computed from match results using the
          Bradley–Terry model and normalized. The whiskers represent 90%
          confidence intervals from our bootstrapping process.
        </figcaption>
      </figure>
    </Section>

    <!-- <Section title="YouTube video">
      <YouTubeVideo videoId="wjZofJX0v4M" />
    </Section> -->

    <!-- <Section title="PDF">
      <PDF source="https://arxiv.org/pdf/1706.03762" />
    </Section> -->

    <Section title="BibTeX citation">
      <code class="whitespace-pre-line">
        {
          `@misc{costarelli2024gamebench,
  title={GameBench: Evaluating Strategic Reasoning Abilities of LLM Agents}, 
  author={Anthony Costarelli and Mat Allen and Roman Hauksson and Grace Sodunke and Suhas Hariharan and Carlson Cheng and Wenjie Li and Arjun Yadav},
  year={2024},
  eprint={2406.06613},
  archivePrefix={arXiv},
  primaryClass={id='cs.CL' full_name='Computation and Language' is_active=True alt_name='cmp-lg' in_archive='cs' is_general=False description='Covers natural language processing. Roughly includes material in ACM Subject Class I.2.7. Note that work on artificial languages (programming languages, logics, formal systems) that does not explicitly address natural-language issues broadly construed (natural-language processing, computational linguistics, speech, text retrieval, etc.) is not appropriate for this area.'}
}`
        }
      </code>
      <pre></pre>
    </Section>
  </main>
  <footer class="m-auto">
    <p class="text-slate-600">
      This page was built using Roman Hauksson's <a
        class="text-blue-500 hover:underline"
        href="https://github.com/RomanHauksson/academic-project-astro-template"
        >Academic Project Astro template</a
      >, which was adopted from Eliahu Horwitz's <a
        class="text-blue-500 hover:underline"
        href="https://github.com/eliahuhorwitz/Academic-project-page-template"
        >Academic Project Page Template</a
      >, which was adopted from Keunhong Park's <a
        class="text-blue-500 hover:underline"
        href="https://nerfies.github.io/">project page for <i>Nerfies</i></a
      >. It is licensed under a <a
        class="text-blue-500 hover:underline"
        href="http://creativecommons.org/licenses/by-sa/4.0/"
        >Creative Commons Attribution-ShareAlike 4.0 International License</a
      >.
    </p>
  </footer>
</Layout>
